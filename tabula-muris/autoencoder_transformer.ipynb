{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c76fa991-5022-4b5e-9437-9fece200eb28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0+cu102'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9e85b06-f4ff-4db2-b41a-666135817e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCellDataset(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        self.adata = sc.read(file_name)\n",
    "        self.x = self.adata.X\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "   \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx]\n",
    "\n",
    "\n",
    "dataset = SingleCellDataset('./brain_normalized.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9768d750-3347-4b3d-9e43-615cb819788c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size)\n",
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0d9cca-7323-4181-b288-b294fcf87edd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 18585])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_x = next(iter(dataloader))\n",
    "example_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dc5ffd1-dc15-4c02-a6c9-0ef1e30d6f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0809,  0.7513, -0.5763,  ..., -0.5655, -0.0438, -0.6812],\n",
       "        [-0.0809, -0.0248, -0.5763,  ..., -0.0751, -0.0438, -0.6812],\n",
       "        [-0.0809, -1.4846, -0.5763,  ...,  1.2355, -0.0438,  2.0596],\n",
       "        ...,\n",
       "        [-0.0809,  0.5327, -0.5763,  ..., -0.5655, -0.0438, -0.6812],\n",
       "        [-0.0809, -1.4846, -0.5763,  ...,  2.6709, -0.0438, -0.6812],\n",
       "        [-0.0809,  0.4098, -0.3287,  ...,  2.2217, -0.0438,  1.1114]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd4d99c-d235-44a6-ab2c-60479bba60fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 1024,\n",
       " 153]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = int(example_x.shape[-1])\n",
    "\n",
    "to_split = []\n",
    "while dim > 1024:\n",
    "    to_split.append(1024)\n",
    "    dim -= 1024\n",
    "to_split.append(dim)\n",
    "to_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b27fb8-e1ff-44a3-b5ac-2fb93b3dab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "768f45e6-0656-42f2-9ecd-f7894ea00d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3])\n",
      "torch.Size([64, 19, 256])\n"
     ]
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, to_split, embedding_size=256, nhead=8, dropout=0.1, num_layers=6, latent_size=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        self.nhead = nhead\n",
    "        self.to_split = to_split\n",
    "        \n",
    "        for i, dim in enumerate(to_split):\n",
    "            e = nn.Sequential(\n",
    "                nn.Linear(dim, embedding_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(embedding_size, embedding_size),\n",
    "            )\n",
    "            setattr(self, f'embedding_{i}', e)\n",
    "        \n",
    "        d_model = embedding_size\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dropout=dropout)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.ave = nn.AvgPool1d(embedding_size)\n",
    "        self.latent = nn.Linear(len(self.to_split), latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s = torch.split(x, self.to_split, dim=1)\n",
    "        z = []\n",
    "        for i in range(len(self.to_split)):\n",
    "            e = getattr(self, f'embedding_{i}')\n",
    "            z.append(e(s[i]))\n",
    "        z = torch.stack(z, dim=1)\n",
    "        encoded = self.encoder(z)\n",
    "        z = self.ave(encoded)\n",
    "        z = torch.reshape(z, [-1, len(self.to_split)])\n",
    "        z = self.latent(z)\n",
    "        return z, encoded\n",
    "\n",
    "\n",
    "encoder = Encoder(to_split).to(device)\n",
    "z, encoded = encoder(example_x.to(device))\n",
    "print(z.shape)\n",
    "print(encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94b9b5f0-a068-4a9c-8e9d-4ebdebd62a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 18585])\n"
     ]
    }
   ],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, to_split, embedding_size=256, nhead=8, dropout=0.1, num_layers=6, latent_size=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.to_split = to_split\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.latent = nn.Linear(latent_size, len(self.to_split) * embedding_size)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embedding_size, nhead=nhead, dropout=dropout)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        for i, dim in enumerate(to_split):\n",
    "            o = nn.Sequential(\n",
    "                nn.Linear(embedding_size, embedding_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(embedding_size, dim),\n",
    "            )\n",
    "            setattr(self, f'output_{i}', o)\n",
    "        \n",
    "    def forward(self, x, encoded):\n",
    "        z = self.latent(x)\n",
    "        z = torch.reshape(z, [-1, len(self.to_split), self.embedding_size])\n",
    "        z = self.decoder(z, encoded)\n",
    "        \n",
    "        s = torch.split(z, 1, dim=1)\n",
    "        output = []\n",
    "        for i in range(len(self.to_split)):\n",
    "            o = getattr(self, f'output_{i}')\n",
    "            s2 = torch.reshape(s[i], [-1, self.embedding_size])\n",
    "            output.append(o(s2))\n",
    "        output = torch.concat(output, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "decoder = Decoder(to_split).to(device)\n",
    "y = decoder(z, encoded)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d430ea-7291-432a-b1dd-c7a81e24f0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 18585])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, to_split, embedding_size=512, nhead=8, dropout=0.0, num_layers=8, latent_size=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(to_split, embedding_size, nhead, dropout, num_layers, latent_size)\n",
    "        self.decoder = Decoder(to_split, embedding_size, nhead, dropout, num_layers, latent_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z, encoded = self.encoder(x)\n",
    "        y = self.decoder(z, encoded)\n",
    "        return y\n",
    "        \n",
    "\n",
    "model = AutoEncoder(to_split).to(device)\n",
    "y = model(example_x.to(device))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6cafd6-9580-42d7-bc8a-9d022d862a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4522fc4b-738b-4706-83f4-7622e4bfa36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.063663\n",
      "loss: 1.194027\n",
      "loss: 1.116905\n",
      "loss: 0.776303\n",
      "loss: 0.811574\n",
      "loss: 0.982197\n",
      "loss: 1.116492\n",
      "loss: 1.082717\n",
      "loss: 0.884367\n",
      "loss: 1.373050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m101\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>7f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dataloader)\u001b[0m\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 12\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/_functional.py:110\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    105\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    109\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[0;32m--> 110\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train(dataloader):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, X in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "\n",
    "        X_pred = model(X)\n",
    "        loss = loss_fn(X_pred, X)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(dataloader)\n",
    "    print(f'loss: {loss:>7f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f17e3-99b6-429e-a131-027e73fd044f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
