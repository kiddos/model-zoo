{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "tensorflow version 2.3.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.callbacks as callbacks\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "print('tensorflow version', tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    "# TARGET_FILE = 'shakespeare.txt'\n",
    "\n",
    "# path_to_file = tf.keras.utils.get_file(TARGET_FILE, URL)\n",
    "# with open(path_to_file, 'rb') as f:\n",
    "#   text = f.read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "char size:  67\n",
      "(1003854,)\n",
      "<BatchDataset shapes: (161,), types: tf.int64>\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 160\n",
    "\n",
    "ds = tfds.load('tiny_shakespeare')\n",
    "\n",
    "for example in ds['train'].take(1):\n",
    "  text = example['text'].numpy().decode('utf-8')\n",
    "  vocab = sorted(set(text))\n",
    "  print(vocab)\n",
    "  \n",
    "  chars_to_index = keras.layers.experimental.preprocessing.StringLookup(vocabulary=list(vocab))\n",
    "  VOCAB_SIZE = len(chars_to_index.get_vocabulary())\n",
    "  print('char size: ', VOCAB_SIZE)\n",
    "  \n",
    "  text = tf.strings.unicode_split(text, input_encoding='UTF-8')\n",
    "  print(text.shape)\n",
    "  \n",
    "  seq = chars_to_index(text)\n",
    "  training_ds = tf.data.Dataset.from_tensor_slices(seq)\n",
    "  training_ds = training_ds.batch(SEQUENCE_LENGTH + 1, drop_remainder=True)\n",
    "  print(training_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((64, 160), (64, 160)), types: (tf.int64, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "def seq_to_seq(seq):\n",
    "  return seq[:-1], seq[1:]\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "target_ds = (training_ds.map(seq_to_seq)\n",
    "  .shuffle(buffer_size=1000)\n",
    "  .batch(BATCH_SIZE, drop_remainder=True)\n",
    "  .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "print(target_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 160)\n",
      "(64, 160)\n",
      "tf.Tensor(\n",
      "[60 48 45  3 53 49 44 44 52 45  3 41 54 44  3 42 61 60  3 55 54 45  3 48\n",
      " 41 52 46  3 55 46  3 63 48 41 60  3 48 45  3 63 41 59  2 65 45 59 60 45\n",
      " 58 44 41 65 13  3 46 55 58  3 60 48 45  3 55 60 48 45 58  3 48 41 59  3\n",
      " 48 41 52 46  8  3 42 65  3 60 48 45  3 45 54 60 58 45 41 60 65  2 41 54\n",
      " 44  3 47 58 41 54 60  3 55 46  3 60 48 45  3 63 48 55 52 45  3 60 41 42\n",
      " 52 45 10  3 22 45  7 52 52  3 47 55  8  3 48 45  3 59 41 65 59  8  2 41\n",
      " 54 44  3 59 55 63 52  3 60 48 45  3 56 55 58 60], shape=(160,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[48 45  3 53 49 44 44 52 45  3 41 54 44  3 42 61 60  3 55 54 45  3 48 41\n",
      " 52 46  3 55 46  3 63 48 41 60  3 48 45  3 63 41 59  2 65 45 59 60 45 58\n",
      " 44 41 65 13  3 46 55 58  3 60 48 45  3 55 60 48 45 58  3 48 41 59  3 48\n",
      " 41 52 46  8  3 42 65  3 60 48 45  3 45 54 60 58 45 41 60 65  2 41 54 44\n",
      "  3 47 58 41 54 60  3 55 46  3 60 48 45  3 63 48 55 52 45  3 60 41 42 52\n",
      " 45 10  3 22 45  7 52 52  3 47 55  8  3 48 45  3 59 41 65 59  8  2 41 54\n",
      " 44  3 59 55 63 52  3 60 48 45  3 56 55 58 60 45], shape=(160,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for example_inputs, example_output in target_ds.take(1):\n",
    "  print(example_inputs.shape)\n",
    "  print(example_output.shape)\n",
    "  print(example_inputs[0])\n",
    "  print(example_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 160, 67) # (batch_size, sequence_length, vocab_size)\n",
      "Model: \"gru_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  17152     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  68675     \n",
      "=================================================================\n",
      "Total params: 4,024,131\n",
      "Trainable params: 4,024,131\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "class GRUModel(keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else: \n",
    "      return x\n",
    "\n",
    "\n",
    "def build_rnn_model():\n",
    "  model =  GRUModel(\n",
    "    vocab_size=len(chars_to_index.get_vocabulary()),\n",
    "    embedding_dim=EMBEDDING_SIZE,\n",
    "    rnn_units=RNN_UNITS)\n",
    "  model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = build_rnn_model()\n",
    "\n",
    "for input_example_batch, target_example_batch in target_ds.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
      "Epoch 1/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 2.9821 - accuracy: 0.2326\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 2/30\n",
      "97/97 [==============================] - 5s 49ms/step - loss: 2.2215 - accuracy: 0.3621\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 3/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.9657 - accuracy: 0.4246\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 4/30\n",
      "97/97 [==============================] - 5s 49ms/step - loss: 1.7716 - accuracy: 0.4769\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 5/30\n",
      "97/97 [==============================] - 5s 49ms/step - loss: 1.6317 - accuracy: 0.5143\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 6/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.5304 - accuracy: 0.5416\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 7/30\n",
      "97/97 [==============================] - 5s 49ms/step - loss: 1.4549 - accuracy: 0.5614\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 8/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.3969 - accuracy: 0.5761\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 9/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.3490 - accuracy: 0.5882\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 10/30\n",
      "97/97 [==============================] - 5s 49ms/step - loss: 1.3099 - accuracy: 0.5978\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 11/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.2730 - accuracy: 0.6076\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 12/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.2391 - accuracy: 0.6166\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 13/30\n",
      "97/97 [==============================] - 5s 49ms/step - loss: 1.2049 - accuracy: 0.6254\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 14/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.1731 - accuracy: 0.6342\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 15/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.1396 - accuracy: 0.6432\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 16/30\n",
      "97/97 [==============================] - 5s 49ms/step - loss: 1.1051 - accuracy: 0.6530\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 17/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.0693 - accuracy: 0.6637\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 18/30\n",
      "97/97 [==============================] - 5s 50ms/step - loss: 1.0317 - accuracy: 0.6751\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 19/30\n",
      "97/97 [==============================] - 5s 51ms/step - loss: 0.9919 - accuracy: 0.6872\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 20/30\n",
      "97/97 [==============================] - 5s 54ms/step - loss: 0.9498 - accuracy: 0.7005\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0001.\n",
      "Epoch 21/30\n",
      "97/97 [==============================] - 5s 53ms/step - loss: 0.8538 - accuracy: 0.7361\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 22/30\n",
      "97/97 [==============================] - 5s 52ms/step - loss: 0.8225 - accuracy: 0.7482\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 23/30\n",
      "97/97 [==============================] - 5s 53ms/step - loss: 0.8098 - accuracy: 0.7529\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 24/30\n",
      "97/97 [==============================] - 5s 53ms/step - loss: 0.7998 - accuracy: 0.7562\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 25/30\n",
      "97/97 [==============================] - 5s 53ms/step - loss: 0.7907 - accuracy: 0.7596\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 26/30\n",
      "97/97 [==============================] - 5s 52ms/step - loss: 0.7815 - accuracy: 0.7628\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 27/30\n",
      "97/97 [==============================] - 5s 53ms/step - loss: 0.7726 - accuracy: 0.7661\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 28/30\n",
      "97/97 [==============================] - 5s 53ms/step - loss: 0.7639 - accuracy: 0.7691\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 29/30\n",
      "97/97 [==============================] - 5s 53ms/step - loss: 0.7551 - accuracy: 0.7723\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 9.999999747378752e-05.\n",
      "Epoch 30/30\n",
      "97/97 [==============================] - 5s 53ms/step - loss: 0.7464 - accuracy: 0.7755\n"
     ]
    }
   ],
   "source": [
    "def scheduler(epoch, lr):\n",
    "  if epoch == 0:\n",
    "    return 1e-3\n",
    "  if epoch == 20:\n",
    "    return 1e-4\n",
    "  return lr\n",
    "\n",
    "\n",
    "schedule_callback = callbacks.LearningRateScheduler(scheduler, verbose=True)\n",
    "\n",
    "history = model.fit(target_ds, epochs=30,\n",
    "                    callbacks=[schedule_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:16<00:00, 130.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIET:\n",
      "And so did I, a great suspicion: but\n",
      "I cannot speak a word of his own royal pires;\n",
      "And so he says, in a few words for my bosom,\n",
      "And be the stronger than the sea, and let him\n",
      "show your father's blood.\n",
      "\n",
      "LUCIO:\n",
      "\n",
      "ISABELLA:\n",
      "Alas, poor soul!\n",
      "\n",
      "ANGELO:\n",
      "What is the matter?\n",
      "\n",
      "MENENIUS:\n",
      "I will be satisfied.\n",
      "\n",
      "Provost:\n",
      "I would they were a beggar to his children's loss,\n",
      "And see how he hath something in the state\n",
      "Of the deep issues; and therefore have you all\n",
      "from the heavens have strong and tell him with a viserable and\n",
      "The very blood of my own life did stand and\n",
      "see him out.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "The ship spirits in the sun.\n",
      "\n",
      "PAULINA:\n",
      "There is no other way\n",
      "Unto the stroke of fortune and the sun\n",
      "And with thy state and in the house of York\n",
      "May she had left us out another and my father,\n",
      "And therefore has a serious man; and then\n",
      "I came to thee and the present at the people,\n",
      "And that the sun hath set the sea for the world,\n",
      "That they are gone to keep your part in justice,\n",
      "That is not heaven and enter them for\n",
      "the shepherd's daughter.\n",
      "\n",
      "AUTOLYCUS:\n",
      "I will not stay the stronger than a word, as thoughts,\n",
      "I will not stay the stronger than the sea,\n",
      "And so he says he is come to know the crown.\n",
      "\n",
      "WARWICK:\n",
      "And I that hath the strength of mine honour,\n",
      "I will not stay the fault and threaten you of her.\n",
      "\n",
      "LUCIO:\n",
      "That's a torch for me; and then the truth of his bed,\n",
      "And make him be a propheter-shed with grief.\n",
      "\n",
      "GLOUCESTER:\n",
      "And so did I; and then the truth of his bed,\n",
      "And make him be a propheter'd body, or the deed.\n",
      "\n",
      "LUCIO:\n",
      "I was not made a fresh words and there to look upon me.\n",
      "\n",
      "CLIFFORD:\n",
      "I would your honour will command me as the matter,\n",
      "The more I should be consul.\n",
      "\n",
      "CORIOLANUS:\n",
      "I will be satisfied;\n",
      "And therefore I say true. I have done thee\n",
      "As thou art fled, to cheer his daughter to his brother,\n",
      "Are you my wife and parting with a blow.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "I pray you, sir, he hath some sign to do it.\n",
      "\n",
      "LUCIO:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(prompt, text_length=10000):\n",
    "  seq = chars_to_index(tf.strings.unicode_split(prompt, input_encoding='UTF-8')).numpy().tolist()\n",
    "  states = None\n",
    "  result = [i for i in seq]\n",
    "  for i in tqdm(range(text_length)):\n",
    "    seq_tensor = tf.convert_to_tensor([seq])\n",
    "    p, state = model(seq_tensor, states=states, return_state=True, training=False)\n",
    "    idx = np.argmax(p[0, -1])\n",
    "    seq.append(idx)\n",
    "    result.append(idx)\n",
    "    states = state\n",
    "    if len(seq) > SEQUENCE_LENGTH:\n",
    "      seq = seq[1:]\n",
    "  result_text = ''\n",
    "  for idx in result:\n",
    "    result_text += chars_to_index.get_vocabulary()[idx]\n",
    "  return result_text\n",
    "\n",
    "\n",
    "result = predict('JULIET:')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
