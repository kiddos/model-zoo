{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fea89a0-a931-48da-ab2e-8f3212f144e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 00:34:35.990379: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# model_checkpoint = 'Salesforce/codet5-small'\n",
    "model_checkpoint = 'Salesforce/codet5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eaf7b8c-48de-4457-ac8f-32e714d9ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import Dataset\n",
    "\n",
    "save_root = os.path.join(os.getenv('HOME'), 'datasets', 'methods2test', 'preprocessed')\n",
    "train_data_folder = os.path.join(save_root, 'train')\n",
    "train_dataset = Dataset.load_from_disk(train_data_folder)\n",
    "\n",
    "eval_data_folder = os.path.join(save_root, 'eval')\n",
    "eval_dataset = Dataset.load_from_disk(eval_data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216f05a7-a101-4ca3-85db-2ad5aaca3194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_dataset, \"eval\": eval_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34dab3f7-e742-458f-a6cb-4d9ef54d108d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 36, 6618, 1071, 918, 1086, 861, 12212, 12, 780, 1981, 16, 514, 17833, 13, 1216, 25793, 321, 2278, 10215, 503, 288, 25852, 1719, 1482, 273, 13024, 1482, 12, 4937, 16, 17833, 1769, 309, 16051, 23422, 18, 20305, 18, 14963, 12, 4688, 1482, 3719, 288, 604, 394, 25793, 321, 2278, 10215, 503, 12, 3589, 67, 5572, 67, 16234, 67, 5519, 16, 514, 18, 2139, 2932, 169, 112, 103, 165, 126, 255, 165, 121, 253, 9275, 87, 13, 165, 121, 240, 166, 102, 231, 165, 123, 241, 20305, 168, 237, 119, 167, 227, 228, 176, 125, 239, 165, 121, 240, 169, 230, 126, 168, 109, 238, 166, 240, 116, 167, 236, 105, 169, 99, 239, 3113, 17833, 10019, 289, 987, 32, 2278, 2081, 1482, 34, 1719, 11913, 1482, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 36, 4709, 1071, 918, 1842, 1997, 861, 12212, 3754, 858, 2279, 6325, 1435, 1216, 25793, 321, 2278, 10215, 503, 288, 3956, 809, 24, 2290, 1719, 809, 24, 2290, 273, 394, 3956, 809, 24, 2290, 5621, 1719, 809, 24, 2290, 18, 542, 29425, 12, 4688, 461, 1769, 1719, 809, 24, 2290, 18, 542, 1526, 12, 3767, 1769, 1347, 12, 2972, 2278, 809, 1179, 18, 4720, 809, 858, 3402, 1876, 29425, 12, 4937, 16, 17833, 13, 2934, 15991, 990, 12, 4688, 809, 24, 2290, 1769, 1347, 12, 9893, 8449, 1179, 18, 588, 2408, 639, 13701, 3817, 12, 4937, 13, 2934, 15991, 990, 12, 1397, 639, 13701, 3817, 1769, 1347, 12, 1397, 639, 13701, 3817, 18, 588, 4212, 12, 2278, 907, 743, 18, 588, 2081, 907, 743, 12, 4688, 461, 3719, 2934, 15991, 990, 12, 2011, 1769, 2665, 503, 18, 12339, 12, 15163, 321, 2278, 10215, 503, 18, 1106, 1769, 2665, 503, 18, 12339, 1079, 12, 780, 18, 2139, 2932, 167, 115, 99, 167, 255, 236, 21097, 167, 241, 103, 168, 111, 99, 169, 112, 103, 165, 126, 255, 165, 121, 253, 9275, 87, 13, 176, 125, 239, 165, 121, 240, 169, 230, 126, 168, 109, 238, 166, 240, 116, 167, 236, 105, 169, 99, 239, 3113, 17833, 10019, 1719, 1179, 18, 2681, 861, 12212, 12, 4937, 16, 17833, 1769, 289, 2]}\n",
      "\n",
      "<s>@Override public void runAtOnce(String namespace, String jobName) throws SaturnJobConsoleException { JobStatus jobStatus = getJobStatus(namespace, jobName); if (!JobStatus.READY.equals(jobStatus)) { throw new SaturnJobConsoleException(ERROR_CODE_BAD_REQUEST, String.format(\"该作业(%s)不处于READY状态，不能立即执行\", jobName)); } List<JobServerStatus> jobServersStatus</s>\n",
      "\n",
      "<s>@Test public void testRunAtOnceFailByNoExecutor() throws SaturnJobConsoleException { JobConfig4DB jobConfig4DB = new JobConfig4DB(); jobConfig4DB.setJobName(jobName); jobConfig4DB.setEnabled(true); when(currentJobConfigService.findConfigByNamespaceAndJobName(namespace, jobName)).thenReturn(jobConfig4DB); when(registryCenterService.getCuratorFrameworkOp(namespace)).thenReturn(curatorFrameworkOp); when(curatorFrameworkOp.getChildren(JobNodePath.getServerNodePath(jobName))).thenReturn(null); expectedException.expect(SaturnJobConsoleException.class); expectedException.expectMessage(String.format(\"没有executor接管该作业(%s)，不能立即执行\", jobName)); jobService.runAtOnce(namespace, jobName); }</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiddos/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 256\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    model_inputs = tokenizer(example['source'], max_length=max_input_length, truncation=True)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(example['target'], max_length=max_target_length, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "example_input = tokenize_function(dataset['train'][666])\n",
    "print(example_input)\n",
    "print()\n",
    "print(tokenizer.decode(example_input['input_ids']))\n",
    "print()\n",
    "print(tokenizer.decode(example_input['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e492669b-4a1f-4221-9356-d28e2791f8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/datasets/methods2test/preprocessed/train/cache-56f30d73c9f38bde.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/datasets/methods2test/preprocessed/eval/cache-9df68898e682e550.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 148570\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['source', 'target', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 78534\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_function)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa78d2b4-aff6-4500-abea-af6e302a5247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "batch_size = 4\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-junit\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"eval\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b8c36e6-1e31-4d81-9473-96cb57c2cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 148570\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 371430\n",
      "  Number of trainable parameters = 222882048\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='371430' max='371430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [371430/371430 16:34:03, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.332700</td>\n",
       "      <td>1.573798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.130900</td>\n",
       "      <td>1.556517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.022600</td>\n",
       "      <td>1.563772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.942900</td>\n",
       "      <td>1.581386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.876600</td>\n",
       "      <td>1.587648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.822000</td>\n",
       "      <td>1.595827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>1.610999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.772600</td>\n",
       "      <td>1.617696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.730100</td>\n",
       "      <td>1.628309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.704700</td>\n",
       "      <td>1.634362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-37143\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-37143/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-37143/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-37143/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-37143/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-37143/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-74286\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-74286/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-74286/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-74286/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-74286/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-74286/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-111429\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-111429/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-111429/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-111429/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-111429/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-111429/special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-148572\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-148572/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-148572/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-148572/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-148572/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-148572/special_tokens_map.json\n",
      "Deleting older checkpoint [codet5-base-finetuned-junit/checkpoint-37143] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-185715\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-185715/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-185715/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-185715/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-185715/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-185715/special_tokens_map.json\n",
      "Deleting older checkpoint [codet5-base-finetuned-junit/checkpoint-74286] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-222858\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-222858/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-222858/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-222858/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-222858/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-222858/special_tokens_map.json\n",
      "Deleting older checkpoint [codet5-base-finetuned-junit/checkpoint-111429] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-260001\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-260001/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-260001/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-260001/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-260001/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-260001/special_tokens_map.json\n",
      "Deleting older checkpoint [codet5-base-finetuned-junit/checkpoint-148572] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-297144\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-297144/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-297144/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-297144/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-297144/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-297144/special_tokens_map.json\n",
      "Deleting older checkpoint [codet5-base-finetuned-junit/checkpoint-185715] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-334287\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-334287/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-334287/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-334287/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-334287/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-334287/special_tokens_map.json\n",
      "Deleting older checkpoint [codet5-base-finetuned-junit/checkpoint-222858] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: target, source. If target, source are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 78534\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to codet5-base-finetuned-junit/checkpoint-371430\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-371430/config.json\n",
      "Configuration saved in codet5-base-finetuned-junit/checkpoint-371430/generation_config.json\n",
      "Model weights saved in codet5-base-finetuned-junit/checkpoint-371430/pytorch_model.bin\n",
      "tokenizer config file saved in codet5-base-finetuned-junit/checkpoint-371430/tokenizer_config.json\n",
      "Special tokens file saved in codet5-base-finetuned-junit/checkpoint-371430/special_tokens_map.json\n",
      "Deleting older checkpoint [codet5-base-finetuned-junit/checkpoint-260001] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=371430, training_loss=0.9517405450868833, metrics={'train_runtime': 59643.5073, 'train_samples_per_second': 24.91, 'train_steps_per_second': 6.228, 'total_flos': 2.109574760398848e+17, 'train_loss': 0.9517405450868833, 'epoch': 10.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1153649e-2f86-4367-a56b-e3769fcfab48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
