{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8b5b6a-069a-4665-9268-0130b71bc2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 20:01:28.673771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformers 4.26.0\n",
      "pytorch 1.13.0a0+git49444c3\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "import collections\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import default_data_collator\n",
    "from transformers import pipeline\n",
    "from transformers import get_scheduler\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from accelerate import Accelerator\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "print('transformers', transformers.__version__)\n",
    "print('pytorch', torch.version.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2e9307-ce51-4eb0-b9c2-d1fdcd4062b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class HyperParameters:\n",
    "    chunk_size = 128\n",
    "    model_name = 'gpt2'\n",
    "    batch_size = 8\n",
    "    learning_rate = 5e-5\n",
    "    epochs = 6\n",
    "\n",
    "\n",
    "params = HyperParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea813044-2560-4a13-804b-4ecd2143ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(params.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b952fda-1b0c-45ac-b795-0d2da5dced24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(params.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2757b0ea-3b39-406e-9a29-7012632161c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 50257])\n"
     ]
    }
   ],
   "source": [
    "text = 'This is an example text'\n",
    "\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "token_logits = model(**inputs).logits\n",
    "print(token_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78d4d501-5c11-477f-ac1a-260a43a6440c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset imdb (/home/kiddos/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.013852834701538086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f62a0ec8d034d87a464266d030c6f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dataset = load_dataset('imdb')\n",
    "imdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6e17e14-e742-4895-a138-a1365aeb83b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Review: A wonderfully quirky film with enough twists for a sack of pretzels. Parker Posey plays Fay Grim as a sexy, vulnerable, loving mother who may or may not be what she seems. The story is very tongue in cheek, and the dialog skillfully understated. Hints of humor and intrigue, neither of which overpower the characterization Posey pulls off so well. The supporting cast is stellar. The downside? This film needs your full attention, almost to the point of stopping the film and taking notes. Posey has more sex appeal in her lifting of an eyebrow than most actresses have in their entire body. She's worth your time, even if you don't understand the denouement.\n",
      ">>> Label: 1\n",
      "\n",
      ">>> Review: The script for \"Scary Movie 2\" just wasn't ready to go. This is a problem with the film that is blatantly evident, to the actors and the audience alike. Director Keenan Ivory Wayans, and many of the actors are funny people; and so the movie isn't completely humorless. To their credit, the film has several funny moments. But as a whole, \"Scary Movie 2\" is not even close to being as clever and amusing as the original.<br /><br />The first \"Scary Movie\" was a laugh a minute film. It turned the smallest subtleties of the slasher film genre into comedic gold. The humor in \"Scary Movie 2\" is as heavy handed as it is un-original. They even miss obvious opportunities for parody. Two of the movies stars are former cast members of \"Beverly Hills 90210,\" and this was a show that was begging to be parodied! In the final analysis, \"Scary Movie 2\" is like a fine bottle of wine that was opened far too soon. The script needed a lot more time to age. 2 stars out of 5.\n",
      ">>> Label: 0\n",
      "\n",
      ">>> Review: Bad. Bad. Bad. Those three lines sum up this crappy little film that can only attract idiot children and their parents to the cinema. and its... #1 Movie in America! What is this country thinking? Mike Myers looking more like Micheal Jackson. Some Chineese lady that falls asleep within 3 minutes. A lame plot with dirty jokes. It's grotesuque and awful. When Green-Eggs and Ham comes out in 2005 I'll be so happy! (not) Eddie Murphy and Tracy Morgan will probably play two hipsters trying to find the lost Green-Eggs and Ham. They'll try to chase Sam-I-Am and that mean guy who are running away with it. (I hope they don't ruin the classic book.) Don't waste time and money by seeing this.\n",
      ">>> Label: 0\n"
     ]
    }
   ],
   "source": [
    "sample = imdb_dataset['train'].shuffle().select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\"\\n>>> Review: {row['text']}\")\n",
    "    print(f\">>> Label: {row['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5322df-180b-4ee9-8e13-aff9dbf1daf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-75f443390e16035f.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-257af2b2ff337d9f.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-83500f3e8a9f2e02.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'attention_mask'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'])\n",
    "\n",
    "\n",
    "tokenized_datasets = imdb_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=['text', 'label']\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1f9439e-34ae-405d-9c66-613ef06b3cc6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f355117f-2ac3-4b72-8e2b-71daefea3534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min([len(sample) for sample in tokenized_datasets['train']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5254d059-35f4-4e2a-b8ac-f188a239e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review 0 length: 358'\n",
      "'>>> Review 1 length: 284'\n",
      "'>>> Review 2 length: 119'\n"
     ]
    }
   ],
   "source": [
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a0be622-39db-4381-aa0d-7b804d7ca24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Concatenated reviews length: 761'\n"
     ]
    }
   ],
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a87a634f-94a4-4927-ab0f-a2595c040c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 26399, 314, 3001, 327, 47269, 20958, 12, 56, 23304, 3913, 422, 616, 2008, 3650, 780, 286, 477, 262, 10386, 326, 11191, 340, 618, 340, 373, 717, 2716, 287, 15904, 13, 314, 635, 2982, 326, 379, 717, 340, 373, 12000, 416, 471, 13, 50, 13, 17112, 611, 340, 1683, 3088, 284, 3802, 428, 1499, 11, 4361, 852, 257, 4336, 286, 7328, 3177, 366, 3642, 46927, 1, 314, 1107, 550, 284, 766, 428, 329, 3589, 29847, 1671, 1220, 6927, 1671, 11037, 464, 7110, 318, 19254, 1088, 257, 1862, 14023, 10512, 3710, 3706, 44131, 508, 3382, 284, 2193, 2279, 673, 460, 546, 1204, 13, 554, 1948, 673, 3382, 284, 2962, 607, 32649, 507, 284, 1642, 617, 3297, 286, 11648, 319, 644, 262, 2811, 7289, 68, 1807, 546, 1728, 1964, 2428, 884, 355, 262, 10836, 1810, 290, 3234, 2428, 287, 262, 1578, 1829, 13, 554, 1022, 4737, 7602, 290, 8850, 2853, 44908, 286, 29679, 546, 511, 9317, 319, 4819, 11, 673, 468, 1714, 351, 607, 10512, 4701, 11, 28999, 11, 290, 6405, 1450, 29847, 1671, 1220, 6927, 1671, 11037, 2061, 12847, 502, 546, 314, 3001, 327, 47269, 20958, 12, 56, 23304, 3913, 318, 326, 2319, 812, 2084, 11, 428, 373, 3177, 47642, 13, 16123, 11, 262, 1714, 290, 42156, 8188, 389, 1178, 290, 1290, 1022, 11, 772, 788, 340, 338, 407, 2823, 588, 617, 45858, 925, 8483, 78, 13, 2893, 616, 1499, 3653, 2000, 1064, 340, 14702, 11, 287, 3950, 1714, 290, 42156, 389, 257, 1688, 25629, 287, 14023, 22041, 13, 3412, 17589, 3876, 24626, 805, 11, 15242, 511, 3280, 284, 922, 1468, 2933, 1757, 8092, 11, 550, 1714, 8188, 287, 465, 7328, 29847, 1671, 1220, 6927, 1671, 11037, 40, 466, 35695, 262, 28303, 329, 262, 1109, 326, 597, 1714, 3402, 287, 262, 2646, 318, 3402, 329, 17290, 4959, 2138, 621, 655, 284, 6380, 661, 290, 787, 1637, 284, 307, 3402, 287, 47642, 20550, 287, 2253, 13, 314, 3001, 327, 47269, 20958, 12, 56, 23304, 3913, 318, 257, 922, 2646, 329, 2687, 10291, 284, 2050, 262, 6174, 290, 18821, 357, 3919, 4000, 5292, 8, 286, 14023, 22041, 13, 887, 1107, 11, 428, 2646, 1595, 470, 423, 881, 286, 257, 7110, 13, 1, 40, 1703, 44269, 25, 12550, 1, 318, 257, 6106, 856, 290, 2181, 43787, 2876, 3723, 14540, 13, 632, 1595, 470, 2300, 644, 530, 338, 1964, 5009, 389, 780, 428, 2646, 460, 8941, 307, 2077, 6411, 319, 597, 1241, 13, 1081, 329, 262, 1624, 326, 30424, 4257, 42156, 318, 281, 11353, 8823, 12, 1558, 11, 326, 2125, 470, 2081, 13, 314, 1053, 1775, 371, 12, 4111, 7328, 351, 4257, 42156, 13, 38842, 11, 484, 691, 2897, 617, 42738, 5009, 11, 475, 810, 389, 262, 371, 12, 4111, 7328, 351, 46529, 24477, 11017, 290, 781, 5912, 2248, 544, 30, 2735, 1456, 11, 780, 484, 836, 470, 2152, 13, 383, 976, 2925, 329, 883, 40805, 7862, 2523, 25, 5513, 6511, 82, 25635, 287, 262, 28633, 475, 407, 257, 48852, 271, 287, 6504, 13, 843, 883, 2181, 43787, 19907, 6918, 588, 383, 4373, 28683, 11, 287, 543, 356, 821, 5716, 284, 262, 2524, 286, 18653, 7096, 78, 338, 48836, 4623, 45610, 1559, 11, 475, 407, 257, 12854, 286, 11398, 7424, 319, 29476, 37918, 570, 88, 13, 7413, 13774, 357, 273, 30253, 8, 366, 23352, 12, 20307, 1, 287, 6067, 286, 42156, 11, 262, 14946, 909, 83, 1904, 815, 1011, 656, 1848, 530, 34804, 1346, 3489, 48631, 3580, 1022, 1450, 290, 1466, 25, 612, 389, 645, 35853, 319, 3359, 618, 49798, 3568, 26349, 11, 290, 262, 976, 2314, 307, 531, 329, 257, 582, 13, 554, 1109, 11, 345, 4143, 1839, 470, 766, 4048, 35853, 287, 281, 1605, 2646, 287, 1997, 1790, 286, 8483, 393, 7952, 1931, 313, 3970, 13, 770, 4260, 4274, 12, 20307, 318, 1342, 257, 4274, 3210, 621, 281, 33603, 31193, 2694, 284, 1282, 284, 2846, 30573, 351, 262, 1035, 1460, 286, 1466, 338, 5920, 13, 1532, 691, 284, 3368, 1642, 428, 2099, 286, 2646, 287, 262, 2003, 13, 770, 2646, 318, 3499, 355, 281, 6306, 475, 4952, 645, 43072, 298, 1621, 29847, 1671, 1220, 6927, 1671, 11037, 3198, 1244, 1254, 41276, 329, 5586, 33834, 340, 780, 340, 18105, 319, 523, 867, 30023, 9863, 8643, 2428, 475, 340, 857, 523, 1231, 597, 22024, 540, 20289, 13, 383, 19091, 2058, 1497, 351, 645, 649, 22582, 357, 25252, 530, 2058, 510, 351, 530, 981, 530, 338, 2000, 11569, 364, 11, 355, 340, 481, 31338, 466, 1141, 428, 27158, 2646, 737, 27, 1671, 1220, 6927, 1671, 11037, 3198, 1244, 1365, 4341, 530, 338, 640, 16143, 503, 257, 4324, 379, 257, 5509, 3957, 29847, 1671, 1220, 6927, 1671, 11037]\n"
     ]
    }
   ],
   "source": [
    "print(concatenated_examples['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8ee2298-551d-46e6-831f-69e619d45e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ids\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n"
     ]
    }
   ],
   "source": [
    "total_length = ((total_length + params.chunk_size -1) // params.chunk_size) * params.chunk_size\n",
    "\n",
    "chunks = {}\n",
    "for k, t in concatenated_examples.items():\n",
    "    t = np.pad(t, (0, total_length - len(t)))\n",
    "    chunks[k] = [t[i : i + params.chunk_size] for i in range(0, total_length, params.chunk_size)]\n",
    "\n",
    "\n",
    "print('input ids')\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f311770-120c-4d82-8fcf-244fd3205ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-dd6518da9fe8c3dd.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-b7ce2daeaa52bd16.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-23495e02fa7d5cb8.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 58542\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 57203\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 117415\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = ((total_length + params.chunk_size -1) // params.chunk_size) * params.chunk_size\n",
    "    result = {}\n",
    "    for k, t in concatenated_examples.items():\n",
    "        t = np.pad(t, (0, total_length - len(t)))\n",
    "        result[k] = [t[i : i + params.chunk_size] for i in range(0, total_length, params.chunk_size)]\n",
    "    result['labels'] = result['input_ids'].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d19542bb-42a6-4b25-af1d-f5c73f164957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adb46789-c589-4bd1-9506-ecf9de0c623c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets['train'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b8b7503-5d04-40af-b487-9b3e3a63b1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 26399, 314, 3001, 327, 47269, 20958, 12, 56, 23304, 3913, 422, 616, 2008, 3650, 780, 286, 477, 262, 10386, 326, 11191, 340, 618, 340, 373, 717, 2716, 287, 15904, 13, 314, 635, 2982, 326, 379, 717, 340, 373, 12000, 416, 471, 13, 50, 13, 17112, 611, 340, 1683, 3088, 284, 3802, 428, 1499, 11, 4361, 852, 257, 4336, 286, 7328, 3177, 366, 3642, 46927, 1, 314, 1107, 550, 284, 766, 428, 329, 3589, 29847, 1671, 1220, 6927, 1671, 11037, 464, 7110, 318, 19254, 1088, 257, 1862, 14023, 10512, 3710, 3706, 44131, 508, 3382, 284, 2193, 2279, 673, 460, 546, 1204, 13, 554, 1948, 673, 3382, 284, 2962, 607, 32649, 507, 284, 1642, 617, 3297, 286, 11648, 319, 644, 262, 2811, 7289, 68, 1807, 546, 1728, 1964, 2428]\n",
      "[40, 26399, 314, 3001, 327, 47269, 20958, 12, 56, 23304, 3913, 422, 616, 2008, 3650, 780, 286, 477, 262, 10386, 326, 11191, 340, 618, 340, 373, 717, 2716, 287, 15904, 13, 314, 635, 2982, 326, 379, 717, 340, 373, 12000, 416, 471, 13, 50, 13, 17112, 611, 340, 1683, 3088, 284, 3802, 428, 1499, 11, 4361, 852, 257, 4336, 286, 7328, 3177, 366, 3642, 46927, 1, 314, 1107, 550, 284, 766, 428, 329, 3589, 29847, 1671, 1220, 6927, 1671, 11037, 464, 7110, 318, 19254, 1088, 257, 1862, 14023, 10512, 3710, 3706, 44131, 508, 3382, 284, 2193, 2279, 673, 460, 546, 1204, 13, 554, 1948, 673, 3382, 284, 2962, 607, 32649, 507, 284, 1642, 617, 3297, 286, 11648, 319, 644, 262, 2811, 7289, 68, 1807, 546, 1728, 1964, 2428]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(lm_datasets['train'][0]['input_ids'])\n",
    "print(lm_datasets['train'][0]['labels'])\n",
    "print(lm_datasets['train'][0]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b590164-6f6a-4731-88b4-a9a32ec01a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30aa0f7d-5120-4797-9343-9d04966d4a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 52687\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 5855\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size = len(lm_datasets['train'])\n",
    "train_size = int(0.9 * data_size)\n",
    "test_size = data_size - train_size\n",
    "\n",
    "downsampled_dataset = lm_datasets['train'].train_test_split(\n",
    "    train_size=train_size, test_size=test_size,\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47d5d233-d319-421b-82ca-74b0d881c594",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    downsampled_dataset['train'],\n",
    "    shuffle=True,\n",
    "    batch_size=params.batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    downsampled_dataset['test'], batch_size=params.batch_size, collate_fn=default_data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6db8f42-d958-422d-8e02-553ce8596a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "optimizer = AdamW(model.parameters(), lr=params.learning_rate)\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8578f8e4-c79b-47e7-86b0-902dc9eca043",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = params.epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c95f02d8-141c-4ca8-b33a-af826ef0059b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49.6785, device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluation(model):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(accelerator.gather(loss.repeat(params.batch_size)))\n",
    "        \n",
    "    losses = torch.cat(losses)\n",
    "    losses = losses[: len(downsampled_dataset['test'])]\n",
    "    try:\n",
    "        perplexity = torch.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "    return perplexity\n",
    "\n",
    "\n",
    "evaluation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f86728b8-bcec-4ec2-8d79-1e3c1cb59cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009908437728881836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 39516,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2504a1c39a14b04bde2cfd9509561bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39516 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 0: Perplexity: 37.515811920166016\n",
      ">>> Epoch 1: Perplexity: 36.330135345458984\n",
      ">>> Epoch 2: Perplexity: 35.84846115112305\n",
      ">>> Epoch 3: Perplexity: 35.65235900878906\n",
      ">>> Epoch 4: Perplexity: 35.824527740478516\n",
      ">>> Epoch 5: Perplexity: 35.863651275634766\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "output_dir = f'{params.model_name}-imdb'\n",
    "\n",
    "for epoch in range(params.epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    perplexity = evaluation(model)\n",
    "    print(f\">>> Epoch {epoch}: Perplexity: {perplexity}\")\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b91d420-24b1-4536-a8f5-98ea4137dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c54f2b5c-2508-4c8c-ba88-da6cbe7a4cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiddos/.local/lib/python3.8/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"I enjoy when movies are made so they can appeal to a wide audience, and this movie certainly delivers.<br /><br />But, this film goes beyond what most films can deliver by simply putting on a little bit of personality on top of the material. I think that it becomes realistic to the human nature of human beings, especially at a time when you are dealing with 9/11. <br /><br />As well as the message it tries to communicate, I appreciate the effort that they put into making this so convincing to the audience (I will say no more about the characters - they've left out a few of the\"}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('I enjoy', max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5ab03df-53b7-4ccd-9b29-e193e2b21291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"This movie was good for sure I hope it works as well for other people like me. This is a must see movie for all children.What can i say about an old, sweet movie? This one has it all: it has an excellent cast, all of them are wonderful. I have always thought of it as a movie that everyone should have had in their life, just because it's a classic. I don't think that I have much to say about Mr. Spielberg (himself at least) other than his amazing story of adventure. The characters are so different and believable and he takes this journey so far that even though it\"}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('This movie', max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0279b958-a773-4e88-8607-0c82adf9b3df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
