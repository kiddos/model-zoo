{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cc4126f-1d22-4fc1-bfa4-fa8345e3f5b7",
   "metadata": {},
   "source": [
    "## Step 1: Training a model in PyTorch\n",
    "To train a model in PyTorch, you first need to define the model architecture using PyTorch's nn module. You can then load your data, define a loss function, and use an optimizer to update the model parameters during training. Here's some sample code to get you started:\n",
    "\n",
    "We are using the MNIST dataset here just for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc6c5009-fd7f-4186-bbcf-56de9cabe91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "  T.ToTensor(),\n",
    "])\n",
    "\n",
    "root = os.path.join(os.getenv('HOME'), 'datasets', 'mnist')\n",
    "train_dataset = MNIST(root, train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cc1e3a-91c2-41be-a2ba-533ded9c8bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_img, sample_label = train_dataset[0]\n",
    "sample_img = sample_img.detach().cpu().numpy()\n",
    "sample_img = sample_img.reshape([28, 28])\n",
    "plt.imshow(sample_img)\n",
    "plt.xlabel(str(sample_label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9fe337b-cd64-4a70-b7be-e0c5dd5c932b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader_args = dict(\n",
    "  batch_size=128\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset,**dataloader_args)\n",
    "test_dataloader = DataLoader(test_dataset, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fda4ed-02fa-4332-9b21-e9d0649ae257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MNISTBaseline(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MNISTBaseline, self).__init__()\n",
    "\n",
    "    self.backbone = nn.Sequential(\n",
    "      nn.Conv2d(1, 16, 3, 1, bias=False),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(3, 2),\n",
    "      nn.Conv2d(16, 32, 3, 1, bias=False),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(3, 2),\n",
    "      nn.Dropout(0.1),\n",
    "    )\n",
    "\n",
    "    self.fc1 = nn.Linear(512, 64)\n",
    "    self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.backbone(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc1(x)\n",
    "    x = F.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "model = MNISTBaseline()\n",
    "sample_x, sample_y = next(iter(train_dataloader))\n",
    "x = model(sample_x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f5e4be-d2c0-464c-86e6-493a41a724bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Average loss: 0.00047813493837602436, Accuracy: 9811/10000 (98.11%)\n",
      "Test: Average loss: 0.00042925924734736327, Accuracy: 9835/10000 (98.35%)\n",
      "Test: Average loss: 0.00041891066540265457, Accuracy: 9828/10000 (98.28%)\n",
      "Test: Average loss: 0.0003605841745840735, Accuracy: 9852/10000 (98.52%)\n",
      "Test: Average loss: 0.00034857125919515963, Accuracy: 9862/10000 (98.62%)\n",
      "Test: Average loss: 0.00037776408895770145, Accuracy: 9860/10000 (98.6%)\n",
      "Test: Average loss: 0.0003587615905991697, Accuracy: 9861/10000 (98.61%)\n",
      "Test: Average loss: 0.00038126383808885294, Accuracy: 9848/10000 (98.48%)\n",
      "Test: Average loss: 0.00037816400647593584, Accuracy: 9857/10000 (98.57%)\n",
      "Test: Average loss: 0.0003905221735081568, Accuracy: 9855/10000 (98.55%)\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "class MNISTTrainer(object):\n",
    "  def __init__(self, **kwargs):\n",
    "    self.__dict__ = dict(kwargs)\n",
    "\n",
    "    self.model = self.model.to(self.device)\n",
    "    self.optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  def train_step(self):\n",
    "    device = self.device\n",
    "    for x, y in self.train_dataloader:\n",
    "      x, y = x.to(device), y.to(device)\n",
    "      self.optimizer.zero_grad()\n",
    "      output = model(x)\n",
    "      loss = self.loss_fn(output, y)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "  def train(self):\n",
    "    self.model.train()\n",
    "    for epoch in range(self.epochs):\n",
    "      self.train_step()\n",
    "      self.evaluate()\n",
    "\n",
    "  def evaluate(self):\n",
    "    self.model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    device = self.device\n",
    "    with torch.no_grad():\n",
    "      for x, y in self.test_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        p = self.model(x)\n",
    "        test_loss += self.loss_fn(p, y).item()\n",
    "        p = p.argmax(dim=1, keepdim=True)\n",
    "        correct += p.eq(y.view_as(p)).sum().item()\n",
    "\n",
    "    datasize = len(self.test_dataloader.dataset)\n",
    "    test_loss /= datasize\n",
    "    print(f'Test: Average loss: {test_loss}, Accuracy: {correct}/{datasize} ({100. * correct / datasize}%)')\n",
    "\n",
    "\n",
    "trainer_args = dict(\n",
    "  epochs=10,\n",
    "  model=model,\n",
    "  train_dataloader=train_dataloader,\n",
    "  test_dataloader=test_dataloader,\n",
    "  device='cuda'\n",
    ")\n",
    "trainer = MNISTTrainer(**trainer_args)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5565f21c-f0a0-4d07-ab4f-b94bc97c1457",
   "metadata": {},
   "source": [
    "## Step 2: Converting the model to ONNX format\n",
    "Once you've trained your model, you can convert it to ONNX format using the torch.onnx.export() function.\n",
    "This function takes your trained PyTorch model, some example inputs, and a filename for the output ONNX file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75976da0-ca08-447b-baa0-b448afae62fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x = torch.randn(1, 1, 28, 28, requires_grad=True)\n",
    "x = x.to('cuda')\n",
    "output = model(x)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,                     # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"mnist.onnx\",              # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a1b8f2-86be-49b1-a49e-1918bcd27a46",
   "metadata": {},
   "source": [
    "## Step 3: Converting the ONNX model to a C file using ONNX2C\n",
    "Finally, you can use ONNX2C to convert your ONNX model to a C file. ONNX2C is a tool that allows you to compile your ONNX model to a C implementation\n",
    "\n",
    "https://github.com/kraiskil/onnx2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68558aeb-4acc-45d2-a4a3-a2d5795022a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!$HOME/projects/onnx2c/build/onnx2c $HOME/projects/model-zoo/notebooks/mnist.onnx -d batch_size:1 > mnist.c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ebc1f-b101-4717-989e-4800eb5abf16",
   "metadata": {},
   "source": [
    "## CIFAR100 example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a832429-f0a2-400c-a42b-f3c079737207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "import torchvision.transforms as T\n",
    "\n",
    "transform = T.Compose([\n",
    "  T.ToTensor(),\n",
    "])\n",
    "\n",
    "root = os.path.join(os.getenv('HOME'), 'datasets', 'cifar100')\n",
    "train_dataset = CIFAR100(root, train=True, download=True, transform=transform)\n",
    "test_dataset = CIFAR100(root, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bcaeafb-fb55-4440-b83d-f8ae6024c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_args = dict(\n",
    "  batch_size=1024\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset,**dataloader_args)\n",
    "test_dataloader = DataLoader(test_dataset, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47043c0d-7d02-4a6b-aeb6-ceae22d05261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR100Baseline(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CIFAR100Baseline, self).__init__()\n",
    "\n",
    "    self.backbone = nn.Sequential(\n",
    "      nn.Conv2d(3, 8, 3, 1, padding=1, bias=False),\n",
    "      nn.BatchNorm2d(8),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(3, 2),  # 8x16x16\n",
    "      nn.Conv2d(8, 16, 3, 1, padding=1, bias=False),\n",
    "      nn.BatchNorm2d(16),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(3, 2),  # 16x8x8\n",
    "      nn.Conv2d(16, 32, 3, 1, padding=1, bias=False),\n",
    "      nn.BatchNorm2d(32),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(3, 2),  # 32x4x4\n",
    "      nn.Conv2d(32, 64, 3, 1, padding=1, bias=False),\n",
    "      nn.BatchNorm2d(64),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(3, 2),  # 64x2x2\n",
    "      nn.Dropout(0.1),\n",
    "    )\n",
    "    self.fc = nn.Linear(64, 100)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.backbone(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = self.fc(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "model = CIFAR100Baseline()\n",
    "sample_x, sample_y = next(iter(train_dataloader))\n",
    "x = model(sample_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "945ce10e-48ef-4389-8925-6731ff370fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Average loss: 0.004196225023269653, Accuracy: 819/10000 (8.19%)\n",
      "Test: Average loss: 0.0036710076570510863, Accuracy: 1489/10000 (14.89%)\n",
      "Test: Average loss: 0.003498375129699707, Accuracy: 1778/10000 (17.78%)\n",
      "Test: Average loss: 0.0033718328714370726, Accuracy: 1989/10000 (19.89%)\n",
      "Test: Average loss: 0.003268707609176636, Accuracy: 2184/10000 (21.84%)\n",
      "Test: Average loss: 0.003197568583488464, Accuracy: 2340/10000 (23.4%)\n",
      "Test: Average loss: 0.003142877244949341, Accuracy: 2457/10000 (24.57%)\n",
      "Test: Average loss: 0.003099172019958496, Accuracy: 2523/10000 (25.23%)\n",
      "Test: Average loss: 0.003059906840324402, Accuracy: 2608/10000 (26.08%)\n",
      "Test: Average loss: 0.0030236181974411013, Accuracy: 2667/10000 (26.67%)\n",
      "Test: Average loss: 0.0029919612884521485, Accuracy: 2758/10000 (27.58%)\n",
      "Test: Average loss: 0.0029636443138122558, Accuracy: 2816/10000 (28.16%)\n",
      "Test: Average loss: 0.0029422213077545164, Accuracy: 2870/10000 (28.7%)\n",
      "Test: Average loss: 0.0029274901151657103, Accuracy: 2894/10000 (28.94%)\n",
      "Test: Average loss: 0.002918732738494873, Accuracy: 2929/10000 (29.29%)\n",
      "Test: Average loss: 0.0029028986215591432, Accuracy: 2938/10000 (29.38%)\n",
      "Test: Average loss: 0.002878710436820984, Accuracy: 3002/10000 (30.02%)\n",
      "Test: Average loss: 0.0028563036918640137, Accuracy: 3060/10000 (30.6%)\n",
      "Test: Average loss: 0.0028544628143310547, Accuracy: 3051/10000 (30.51%)\n",
      "Test: Average loss: 0.0028358699798583984, Accuracy: 3101/10000 (31.01%)\n",
      "Test: Average loss: 0.0028188753604888915, Accuracy: 3134/10000 (31.34%)\n",
      "Test: Average loss: 0.002801345443725586, Accuracy: 3169/10000 (31.69%)\n",
      "Test: Average loss: 0.002793541383743286, Accuracy: 3197/10000 (31.97%)\n",
      "Test: Average loss: 0.0027850525856018067, Accuracy: 3223/10000 (32.23%)\n",
      "Test: Average loss: 0.0027772196769714355, Accuracy: 3242/10000 (32.42%)\n",
      "Test: Average loss: 0.0027672973155975344, Accuracy: 3257/10000 (32.57%)\n",
      "Test: Average loss: 0.00275868706703186, Accuracy: 3271/10000 (32.71%)\n",
      "Test: Average loss: 0.0027538422584533692, Accuracy: 3261/10000 (32.61%)\n",
      "Test: Average loss: 0.002748590421676636, Accuracy: 3272/10000 (32.72%)\n",
      "Test: Average loss: 0.0027538400173187255, Accuracy: 3302/10000 (33.02%)\n",
      "Test: Average loss: 0.002753753209114075, Accuracy: 3316/10000 (33.16%)\n",
      "Test: Average loss: 0.002773590064048767, Accuracy: 3278/10000 (32.78%)\n",
      "Test: Average loss: 0.00276147141456604, Accuracy: 3286/10000 (32.86%)\n",
      "Test: Average loss: 0.002753283929824829, Accuracy: 3294/10000 (32.94%)\n",
      "Test: Average loss: 0.002747346591949463, Accuracy: 3301/10000 (33.01%)\n",
      "Test: Average loss: 0.0027418128728866576, Accuracy: 3305/10000 (33.05%)\n",
      "Test: Average loss: 0.0027438695192337037, Accuracy: 3287/10000 (32.87%)\n",
      "Test: Average loss: 0.002734887385368347, Accuracy: 3307/10000 (33.07%)\n",
      "Test: Average loss: 0.0027279942750930786, Accuracy: 3322/10000 (33.22%)\n",
      "Test: Average loss: 0.002725656604766846, Accuracy: 3313/10000 (33.13%)\n",
      "Test: Average loss: 0.002716946291923523, Accuracy: 3328/10000 (33.28%)\n",
      "Test: Average loss: 0.0027115775346755982, Accuracy: 3342/10000 (33.42%)\n",
      "Test: Average loss: 0.002705579733848572, Accuracy: 3362/10000 (33.62%)\n",
      "Test: Average loss: 0.0027038960933685303, Accuracy: 3387/10000 (33.87%)\n",
      "Test: Average loss: 0.002699499201774597, Accuracy: 3416/10000 (34.16%)\n",
      "Test: Average loss: 0.002703868508338928, Accuracy: 3414/10000 (34.14%)\n",
      "Test: Average loss: 0.002713037323951721, Accuracy: 3406/10000 (34.06%)\n",
      "Test: Average loss: 0.0027371235609054564, Accuracy: 3374/10000 (33.74%)\n",
      "Test: Average loss: 0.0027143325090408323, Accuracy: 3415/10000 (34.15%)\n",
      "Test: Average loss: 0.002703060173988342, Accuracy: 3437/10000 (34.37%)\n"
     ]
    }
   ],
   "source": [
    "class CIFAR100Trainer(object):\n",
    "  def __init__(self, **kwargs):\n",
    "    self.__dict__ = dict(kwargs)\n",
    "\n",
    "    self.model = self.model.to(self.device)\n",
    "    self.optimizer = AdamW(model.parameters(), lr=1e-3)\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "  def train_step(self):\n",
    "    device = self.device\n",
    "    for x, y in self.train_dataloader:\n",
    "      x, y = x.to(device), y.to(device)\n",
    "      self.optimizer.zero_grad()\n",
    "      output = model(x)\n",
    "      loss = self.loss_fn(output, y)\n",
    "      loss.backward()\n",
    "      self.optimizer.step()\n",
    "\n",
    "  def train(self):\n",
    "    self.model.train()\n",
    "    for epoch in range(self.epochs):\n",
    "      self.train_step()\n",
    "      self.evaluate()\n",
    "\n",
    "  def evaluate(self):\n",
    "    self.model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    device = self.device\n",
    "    with torch.no_grad():\n",
    "      for x, y in self.test_dataloader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        p = self.model(x)\n",
    "        test_loss += self.loss_fn(p, y).item()\n",
    "        p = p.argmax(dim=1, keepdim=True)\n",
    "        correct += p.eq(y.view_as(p)).sum().item()\n",
    "\n",
    "    datasize = len(self.test_dataloader.dataset)\n",
    "    test_loss /= datasize\n",
    "    print(f'Test: Average loss: {test_loss}, Accuracy: {correct}/{datasize} ({100. * correct / datasize}%)')\n",
    "\n",
    "\n",
    "trainer_args = dict(\n",
    "  epochs=50,\n",
    "  model=model,\n",
    "  train_dataloader=train_dataloader,\n",
    "  test_dataloader=test_dataloader,\n",
    "  device='cuda'\n",
    ")\n",
    "trainer = CIFAR100Trainer(**trainer_args)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ac3b543-5149-4337-8ea5-ae73c07c2592",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x = torch.randn(1, 3, 32, 32, requires_grad=True)\n",
    "model.to('cpu')\n",
    "output = model(x)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,                     # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"cifar100.onnx\",           # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=11,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc472005-b895-4d57-91ad-64f040582395",
   "metadata": {},
   "outputs": [],
   "source": [
    "!$HOME/projects/onnx2c/build/onnx2c $HOME/projects/model-zoo/notebooks/cifar100.onnx -d batch_size:1 > cifar100.c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9cba8b-03c7-4b20-9bcc-ca0913f3d69a",
   "metadata": {},
   "source": [
    "## Caveat\n",
    "\n",
    "RNN doesn't seem to be able to convert to onnx\n",
    "\n",
    "- LSTMs\n",
    "- GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef30ffc-1dd6-423e-b9e2-a59febfd1856",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "1. train the model\n",
    "2. Convert to ONNX\n",
    "3. run `./onnx2c model.onnx -d batch_size:1 > model.c`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bb9b5c-1b2c-4347-90e9-a24799ed9644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
