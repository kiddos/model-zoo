{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e017336c-b359-4e72-9d73-5871124da5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-29 04:40:51.135041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.26.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf088159-d9dc-4a8a-9313-64140d279adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-ro\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17fffb1-53f9-4dc9-9b10-f453f80e8b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset wmt16 (/home/kiddos/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014248371124267578,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a9b85fcb6f4d0283dc78b1b3a33d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_593530/660267480.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "raw_datasets = load_dataset(\"wmt16\", \"ro-en\")\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a72564-989c-4568-847f-1152ac2a0908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 610320\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1999\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation'],\n",
       "        num_rows: 1999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2a6621-9c39-4407-89a8-b459d1e42e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'translation': {'en': 'Membership of Parliament: see Minutes',\n",
       "  'ro': 'ComponenÅ£a Parlamentului: a se vedea procesul-verbal'}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d67917-dea1-40b3-8824-3e6a155e63eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'en': 'Approval of the minutes of the previou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'en': 'Essential opportunities for increasing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'en': 'At the same time, the Member States wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'en': 'Logically speaking, if these are good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'en': 'The European Union must show its solid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         translation\n",
       "0  {'en': 'Approval of the minutes of the previou...\n",
       "1  {'en': 'Essential opportunities for increasing...\n",
       "2  {'en': 'At the same time, the Member States wi...\n",
       "3  {'en': 'Logically speaking, if these are good ...\n",
       "4  {'en': 'The European Union must show its solid..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    return df\n",
    "\n",
    "\n",
    "show_random_elements(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f88e26a7-9f4c-490f-8bcc-1de19991c8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metric(name: \"sacrebleu\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, usage: \"\"\"\n",
       "Produces BLEU scores along with its sufficient statistics\n",
       "from a source against one or more references.\n",
       "\n",
       "Args:\n",
       "    predictions (`list` of `str`): list of translations to score. Each translation should be tokenized into a list of tokens.\n",
       "    references (`list` of `list` of `str`): A list of lists of references. The contents of the first sub-list are the references for the first prediction, the contents of the second sub-list are for the second prediction, etc. Note that there must be the same number of references for each prediction (i.e. all sub-lists must be of the same length).\n",
       "    smooth_method (`str`): The smoothing method to use, defaults to `'exp'`. Possible values are:\n",
       "        - `'none'`: no smoothing\n",
       "        - `'floor'`: increment zero counts\n",
       "        - `'add-k'`: increment num/denom by k for n>1\n",
       "        - `'exp'`: exponential decay\n",
       "    smooth_value (`float`): The smoothing value. Only valid when `smooth_method='floor'` (in which case `smooth_value` defaults to `0.1`) or `smooth_method='add-k'` (in which case `smooth_value` defaults to `1`).\n",
       "    tokenize (`str`): Tokenization method to use for BLEU. If not provided, defaults to `'zh'` for Chinese, `'ja-mecab'` for Japanese and `'13a'` (mteval) otherwise. Possible values are:\n",
       "        - `'none'`: No tokenization.\n",
       "        - `'zh'`: Chinese tokenization.\n",
       "        - `'13a'`: mimics the `mteval-v13a` script from Moses.\n",
       "        - `'intl'`: International tokenization, mimics the `mteval-v14` script from Moses\n",
       "        - `'char'`: Language-agnostic character-level tokenization.\n",
       "        - `'ja-mecab'`: Japanese tokenization. Uses the [MeCab tokenizer](https://pypi.org/project/mecab-python3).\n",
       "    lowercase (`bool`): If `True`, lowercases the input, enabling case-insensitivity. Defaults to `False`.\n",
       "    force (`bool`): If `True`, insists that your tokenized input is actually detokenized. Defaults to `False`.\n",
       "    use_effective_order (`bool`): If `True`, stops including n-gram orders for which precision is 0. This should be `True`, if sentence-level BLEU will be computed. Defaults to `False`.\n",
       "\n",
       "Returns:\n",
       "    'score': BLEU score,\n",
       "    'counts': Counts,\n",
       "    'totals': Totals,\n",
       "    'precisions': Precisions,\n",
       "    'bp': Brevity penalty,\n",
       "    'sys_len': predictions length,\n",
       "    'ref_len': reference length,\n",
       "\n",
       "Examples:\n",
       "\n",
       "    Example 1:\n",
       "        >>> predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
       "        >>> references = [[\"hello there general kenobi\", \"hello there !\"], [\"foo bar foobar\", \"foo bar foobar\"]]\n",
       "        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
       "        >>> results = sacrebleu.compute(predictions=predictions, references=references)\n",
       "        >>> print(list(results.keys()))\n",
       "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
       "        >>> print(round(results[\"score\"], 1))\n",
       "        100.0\n",
       "\n",
       "    Example 2:\n",
       "        >>> predictions = [\"hello there general kenobi\",\n",
       "        ...                 \"on our way to ankh morpork\"]\n",
       "        >>> references = [[\"hello there general kenobi\", \"hello there !\"],\n",
       "        ...                 [\"goodbye ankh morpork\", \"ankh morpork\"]]\n",
       "        >>> sacrebleu = datasets.load_metric(\"sacrebleu\")\n",
       "        >>> results = sacrebleu.compute(predictions=predictions,\n",
       "        ...                             references=references)\n",
       "        >>> print(list(results.keys()))\n",
       "        ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']\n",
       "        >>> print(round(results[\"score\"], 1))\n",
       "        39.8\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45062f00-79ce-44a3-9749-68fd2fc75a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0,\n",
       " 'counts': [4, 2, 0, 0],\n",
       " 'totals': [4, 2, 0, 0],\n",
       " 'precisions': [100.0, 100.0, 0.0, 0.0],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 4}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = [\"hello there\", \"general kenobi\"]\n",
    "fake_labels = [[\"hello there\"], [\"general kenobi\"]]\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb873356-daa9-461b-8922-8dcd6f1c6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a3feeb7-e6bc-40d2-9213-f9dcf191f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"mbart\" in model_checkpoint:\n",
    "    tokenizer.src_lang = \"en-XX\"\n",
    "    tokenizer.tgt_lang = \"ro-RO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9915a404-7ae9-4c00-b6b0-ea20587598c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [125, 778, 3, 63, 141, 9191, 23, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this one sentence!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efdb0026-3742-435e-b159-ccdbb1ca020c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[125, 778, 3, 63, 141, 9191, 23, 0], [187, 32, 716, 9191, 2, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97350bf7-d39b-4fc1-aeb3-8aec8364552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[10334, 1204, 3, 15, 8915, 27, 452, 59, 29579, 581, 23, 0], [235, 1705, 11, 32, 8, 1205, 5305, 59, 29579, 581, 2, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiddos/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3581: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# To prepare the targets for our model,\n",
    "# we need to tokenize them inside the as_target_tokenizer context manager.\n",
    "# This will make sure the tokenizer uses the special tokens corresponding to the targets:\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    print(tokenizer([\"Hello, this one sentence!\", \"This is another sentence.\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee2d038-8877-47ea-a114-10950eca136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"translate English to Romanian: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ad3ec6-2566-4963-95b8-70b7e1df3ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[393, 4462, 14, 1137, 53, 216, 28636, 0], [24385, 14, 28636, 14, 4646, 4622, 53, 216, 28636, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[42140, 494, 1750, 53, 8, 59, 903, 3543, 9, 15202, 0], [36199, 6612, 9, 15202, 122, 568, 35788, 21549, 53, 8, 59, 903, 3543, 9, 15202, 0]]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"en\"\n",
    "target_lang = \"ro\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "preprocess_function(raw_datasets['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9870acf1-5e73-4717-a93b-6ecbc0baad9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-99c73e08a3b74642.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-1e3ca2e2f63132a0.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/kiddos/huggingface/datasets/wmt16/ro-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-3e4a7c2bc566867e.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 610320\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1999\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1999\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d538563-47a5-488b-ad80-7fcf373dc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a7a47c-314f-4f2b-85e6-35fa38f41ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d9a1bdd-9f49-4414-835c-b31dbd89860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2d5711f-5054-483e-b0da-8ae0651067c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d8248a2-e88d-400f-9802-8be4e3dc7337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "603c15ef-84e0-454e-901d-270d77dc462f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "/home/kiddos/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 610320\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 57219\n",
      "  Number of trainable parameters = 74624512\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57219' max='57219' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [57219/57219 1:56:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.743200</td>\n",
       "      <td>1.280902</td>\n",
       "      <td>27.948900</td>\n",
       "      <td>34.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>1.290291</td>\n",
       "      <td>28.184500</td>\n",
       "      <td>34.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.662700</td>\n",
       "      <td>1.286715</td>\n",
       "      <td>28.256100</td>\n",
       "      <td>34.043500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1500/special_tokens_map.json\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-1500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-2500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-3500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-4500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-5500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-6500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-7500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-8500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-9500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-10500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-11500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-12500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-13500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-14500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-15500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-16500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-17500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1999\n",
      "  Batch size = 32\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-18500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-19500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-20500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-21500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-22500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-23500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-24500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-25500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-26500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-27500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-28500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-29500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-30500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-31500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-32500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-33500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-34500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-35500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-36500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1999\n",
      "  Batch size = 32\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-37500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-38500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-39500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-40500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-41500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-42500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-43500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-44500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-45500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-46500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-47500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-48500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-49500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-50500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-51500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-52500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-53500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-54500] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56500\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56500/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56500/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56500/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56500/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-56500/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55000] due to args.save_total_limit\n",
      "Saving model checkpoint to opus-mt-en-ro-finetuned-en-to-ro/checkpoint-57000\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-57000/config.json\n",
      "Configuration saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-57000/generation_config.json\n",
      "Model weights saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-57000/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-57000/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-ro-finetuned-en-to-ro/checkpoint-57000/special_tokens_map.json\n",
      "Deleting older checkpoint [opus-mt-en-ro-finetuned-en-to-ro/checkpoint-55500] due to args.save_total_limit\n",
      "The following columns in the evaluation set don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation. If translation are not expected by `MarianMTModel.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1999\n",
      "  Batch size = 32\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=57219, training_loss=0.709821655815318, metrics={'train_runtime': 7018.5148, 'train_samples_per_second': 260.876, 'train_steps_per_second': 8.153, 'total_flos': 3.4355530989305856e+16, 'train_loss': 0.709821655815318, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5683dd0-680c-41c1-a174-5394f5ca7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model.to('cpu')\n",
    "translator = pipeline('text2text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62b69456-c837-44b7-9929-9b71ceafb4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generate config GenerationConfig {\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      59542\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 59542,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"max_length\": 512,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 59542,\n",
      "  \"transformers_version\": \"4.26.0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Salutare lume'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca02c5-1c5f-4b72-88a2-0eb07a551a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
