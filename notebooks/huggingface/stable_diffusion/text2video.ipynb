{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aadcf5c-99fd-4458-ae34-6ad4a793a99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246daad304da4c83bb156e941df51129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It seems like you have activated model offloading by calling `enable_model_cpu_offload`, but are now manually moving the pipeline to GPU. It is strongly recommended against doing so as memory gains from offloading are likely to be lost. Offloading automatically takes care of moving the individual components vae, text_encoder, tokenizer, unet, scheduler to GPU when needed. To make sure offloading works as expected, you should consider moving the pipeline back to CPU: `pipeline.to('cpu')` or removing the move altogether if you use offloading.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from diffusers.utils import export_to_video\n",
    "\n",
    "model_id = 'damo-vilab/text-to-video-ms-1.7b'\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "  model_id,\n",
    "  torch_dtype=torch.float16,\n",
    "  variant='fp16'\n",
    ")\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_model_cpu_offload()\n",
    "pipe = pipe.to('cuda')\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "pipe.safety_checker = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ce0785-a2ea-483d-b055-fc99ef4db45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf6280971664be382cea52ecdec746b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = 'Spiderman is surfing'\n",
    "video_frames = pipe(prompt, num_inference_steps=25).frames\n",
    "video_path = export_to_video(video_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7fac2a3-9f87-461a-9929-c4ea32bfe68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmpv55tfzq7.mp4\n"
     ]
    }
   ],
   "source": [
    "print(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31905a1-e4e5-426b-b9e9-f2902df9f367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
