{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a37012-02f6-412d-b131-2472763d5810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e5f18406bd47a4ae59655e2b98efe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"codellama/CodeLlama-7b-hf\", load_in_4bit=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afbce49a-4c48-4ab7-bf31-6d46bf946020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"codellama/CodeLlama-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ba300a-925c-45cf-a7e6-21136d3c190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/home/kiddos/.pyenv/versions/3.11.4/lib/python3.11/site-packages/transformers/generation/utils.py:1539: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "/home/kiddos/.pyenv/versions/3.11.4/lib/python3.11/site-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "def remove_non_ascii(s: str) -> str:\n",
      "  \"\"\" Remove non-ASCII characters from a string.\n",
      "\n",
      "  Args:\n",
      "    s: The string to remove non-ASCII characters from.\n",
      "\n",
      "  Returns:\n",
      "    The string with non-ASCII characters removed.\n",
      "  \"\"\"\n",
      "  result = ''\n",
      "  for c in s:\n",
      "    if ord(c) < 128:\n",
      "      result += c\n",
      "  return result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PROMPT = '''\n",
    "def remove_non_ascii(s: str) -> str:\n",
    "  \"\"\" <FILL_ME>\n",
    "  return result\n",
    "'''\n",
    "\n",
    "input_ids = tokenizer(PROMPT, return_tensors=\"pt\")[\"input_ids\"]\n",
    "input_ids.to('cuda')\n",
    "generated_ids = model.generate(input_ids, max_new_tokens=128)\n",
    "\n",
    "filling = tokenizer.batch_decode(generated_ids[:, input_ids.shape[1]:], skip_special_tokens = True)[0]\n",
    "print(PROMPT.replace(\"<FILL_ME>\", filling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88bcf5aa-7481-4354-a85c-7113d5dd4864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]])\n"
     ]
    }
   ],
   "source": [
    "fill = '''<FILL_ME>'''\n",
    "input_ids = tokenizer(fill, return_tensors=\"pt\")[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63731607-032f-4186-9ce2-9a2084c4166b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1, 9995]])\n"
     ]
    }
   ],
   "source": [
    "fill = '''\"\"\"<FILL_ME>'''\n",
    "input_ids = tokenizer(fill, return_tensors=\"pt\")[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59215bc9-8903-469f-959d-6bc70c933e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   1, 9995]])\n"
     ]
    }
   ],
   "source": [
    "fill = '''\"\"\"'''\n",
    "input_ids = tokenizer(fill, return_tensors=\"pt\")[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e950bc78-5753-4aec-91bd-b96951495f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 32007, 29871,    13,  1753,  3349, 29918,  5464, 29918,   294,\n",
      "         18869, 29898, 29879, 29901,   851, 29897,  1599,   851, 29901,    13,\n",
      "         29871,  9995, 29871, 32008,    13, 32009]])\n"
     ]
    }
   ],
   "source": [
    "x = '''\n",
    "def remove_non_ascii(s: str) -> str:\n",
    "  \"\"\" <FILL_ME>\n",
    "'''\n",
    "input_ids = tokenizer(x, return_tensors=\"pt\")[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5368e217-668a-4064-ad5f-e8c923ee680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 29871,    13,  1753,  3349, 29918,  5464, 29918,   294, 18869,\n",
      "         29898, 29879, 29901,   851, 29897,  1599,   851, 29901,    13]])\n"
     ]
    }
   ],
   "source": [
    "x = '''\n",
    "def remove_non_ascii(s: str) -> str:\n",
    "'''\n",
    "input_ids = tokenizer(x, return_tensors=\"pt\")[\"input_ids\"]\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7aee2bd-5800-48f3-a2b4-d9a36b02d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Remove non-ASCII characters from a string. \"\"\"\\n  result = \\'\\'\\n  for c in s:\\n    if ord(c) < 128:\\n      result += c'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers.pipelines.text_generation import ReturnType\n",
    "import torch\n",
    "\n",
    "generator = pipeline(\n",
    "  \"text-generation\",\n",
    "  model=model,\n",
    "  tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generator(\n",
    "  PROMPT,\n",
    "  max_new_tokens=128,\n",
    "  return_type=ReturnType.NEW_TEXT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c78819-f522-4768-a418-418759b2cc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
